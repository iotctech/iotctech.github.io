<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Hello World</title>
      <link href="2021/02/07/hello-world/"/>
      <url>2021/02/07/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><p><img src="https://iotc.coding.net/p/image/d/image/git/raw/master/blog/287f9a7067511ac746fcecd6128da500ad9abbcd379298fa8f5d0e7712c7d539.gif" alt="picture 2">  </p><p><img src="https://iotc.coding.net/p/image/d/image/git/raw/master/blog/tara-1612026105338.jpg" alt="picture 3">  </p><p><img src="https://iotc.coding.net/p/image/d/image/git/raw/master/blog/-1612339824820.png" alt="picture 4">  </p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>自动驾驶环境感知概述</title>
      <link href="2021/02/05/zi-dong-jia-shi-huan-jing-gan-zhi-gai-shu/"/>
      <url>2021/02/05/zi-dong-jia-shi-huan-jing-gan-zhi-gai-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="1、自动驾驶环境感知介绍"><a href="#1、自动驾驶环境感知介绍" class="headerlink" title="1、自动驾驶环境感知介绍"></a>1、自动驾驶环境感知介绍</h1><p>自动驾驶汽车首先是对环境信息和车内信息的采集、处理与分析，即环境感知，它是智能车辆自主行驶的基础和前提。环境感知的对象主要包括 <strong>路面、静态物体和动态物体</strong> 等三个方面，涉及道路边界检测、障碍物检测、车辆检测、行人检测等技术。对于动态物体，不仅要检测到物体到当前位置，而且要对其轨迹进行跟踪，并根据跟踪结果，预测物体下一步的位置。</p><p><img src="https://iotc.coding.net/p/image/d/image/git/raw/master/blog/-1612662343466.png" alt="环境感知"></p><p>环境感知所用到的传感器一般包括 <strong>激光测距仪、视频摄像头、车载雷达等</strong>。单个传感器一般无法满足各种工况下的精确感知，要想车辆在各种环境下平稳运行，就需要运用到多传感器融合技术，该技术也是环境感知的关键所在。</p><p>检测和识别是自动驾驶中环境感知的两大基本任务，主要是通过机器学习和计算机视觉技术来实现的，也是自动驾驶汽车智能的体现。</p><p>与传统的视觉技术相比，深度学习在自动驾驶中的应用有着诸多优势：  </p><ul><li>能够较为容易的迁移到新的目标种类上，只要获取足够该类别的样本就可以训练得到识别改类别的网络；</li><li>能够提高对遮挡物体的识别准确率，这一优势主要来自卷积神经网络强大的特征提取能力；</li><li>对光线变化相对健壮，能够应对光线较暗的环境，而对于传统的手工设计的特征提取算法来说，光照是一个很大的挑战，神经网络的数据驱动特征提取能力能够很好的应对此类问题。  </li></ul><p>虽然深度卷积神经网络在视觉任务尤其是基于图像的任务取得了巨大的成功，然而对视频分析的能力相对薄弱，因为无人车面对的通常是视频流，不是单个静态图像。视觉深度学习在视频分析上的算法往往从图像领域直接迁移过来，缺乏对时序性的有效描述手段，尚未形成独立的科学问题。</p><h1 id="2、车载感知系统组成简介"><a href="#2、车载感知系统组成简介" class="headerlink" title="2、车载感知系统组成简介"></a>2、车载感知系统组成简介</h1><p>智能驾驶车辆获取和处理环境信息主要用于状态感知和V2X（车对外界的信息交换）网联通信。状态感知主要通过车载传感器对周边及本车环境状态信息进行采集和处理，主要包括交通状态感知和车身状态感知。V2X网联通信是结合现代通信与网络技术，实现智能驾驶车辆与外界设施以及汽车之间的互联互通、信息共享和协同控制等。</p><p>环境感知是一个复杂的系统，它需要多种车载传感器实时获取周边环境的信息，通过多种算法处理和分析原始输入数据，给出最合理的决策。因此，环境感知是硬件设备和软件算法的统一体。</p><p>硬件设备是感知的物理基础，主要指各种车载传感器，包括激光雷达、毫米波雷达、机器视觉系统、红外传感器、超声波传感器、惯性系统、多传感器信息融合系统、多源信息交互系统等。一般而言，原始数据质量越高，后续数据处理和分析模块的难度就越低。各个传感器能够分别获取不同的局部信息，这些信息之间相互补充，多传感器融合取长补短，能够显著提高系统的冗余度和容错性，从而保证决策的快速性和正确性。多传感器融合是当前自动驾驶汽车采用的主流环境感知方案。</p><h2 id="2-1、摄像头"><a href="#2-1、摄像头" class="headerlink" title="2.1、摄像头"></a>2.1、摄像头</h2><p>较之其他传感器，摄像头获取的信息更为直观，接近人类视觉，也更为丰富。例如交通标志、信号灯、道路标志等。对于自动驾驶汽车，摄像头取代人类视觉，成为环境感知的重要传感器之一。机器视觉系统通过摄像头获取从不同角度拍摄的环境信息，通过图像增强、去雾等技术对原始的输入图像进行数据预处理，把经过处理的图像送入视觉分析模块，计算机再通过数字图像处理技术和计算机视觉相关算法对图像或视频进行分析，实现分类、分割、检测、跟踪，提取车道线、行人、车辆、障碍物的位置、尺寸、速度和方向信息，对可能出现的险情进行报警和紧急处理。</p><p>相比于激光雷达，机器视觉系统可以获得如交通灯、公路线和指示牌提供的较为丰富的语义特征，因此具有不可替代的优势。机器视觉具有监控范围广、信息量大、成本较低的优势。</p><p>缺点：尽管机器视觉的发展非常迅猛，在能见度低、光照弱或反光的情景下，对机器视觉系统性能影响较大，而且无法全天候工作。</p><h2 id="2-2、激光雷达"><a href="#2-2、激光雷达" class="headerlink" title="2.2、激光雷达"></a>2.2、激光雷达</h2><p>激光雷达通过电磁波获取目标的位置和速度信息以及周围环境的三维特征。激光雷达的原理非常简单，通过向目标发射探测激光信号，通过分析目标的反射信号获取信息。根据目标的密度信息，就可以轻易的识别汽车、行人、路障、树木、路灯等公路上常见的目标。因此激光雷达的使用环境非常广泛。</p><p>优点：激光雷达分辨率极高，频率比微波高2～3个数量级，测距精度高，角分辨率高，速度分辨率高，测量范围大，还具有抗干扰能力强等优点，因此，激光雷达在汽车防碰撞系统和辅助驾驶系统中已经有广泛的应用。</p><p>缺点：价格高、体积大频率相近的激光雷达之间存在着相互干扰，此外，激光雷达受天气的影响较大，在雾霾、雨雪等能见度较低的环境中，激光雷达可探测距离会极速衰减。</p><p>目前应用较广泛的主要有单线激光雷达和多线激光雷达。单线激光雷达由一个高同频脉冲激光测距仪和一个旋转扫描组成。通过发射一条激光束扫描某个区域，返回发射点到扫描位置的距离和角度。根据距离和实时性要求的不同，可设置不同的频率和角分辨率。多线激光雷达指同时发射两条或两条以上的激光束进行探测的激光雷达。相比于单线激光雷达，多线激光雷达精度更大，但体积、重量和功耗相对较大。</p><h2 id="2-3、毫米波雷达"><a href="#2-3、毫米波雷达" class="headerlink" title="2.3、毫米波雷达"></a>2.3、毫米波雷达</h2><p>毫米波雷达是自动驾驶不可或缺但传感器，它是唯一可以全天候工作但传感器。毫米波雷达具有体积小、角分辨率高、频带宽、探测距离远、抗干扰能力强等优点。它与激光雷达相比，具有较好但指向性和穿透性。然而毫米波雷达最大的弊端是无法探测平行平面内的目标信息。</p><h2 id="2-4、超声波雷达"><a href="#2-4、超声波雷达" class="headerlink" title="2.4、超声波雷达"></a>2.4、超声波雷达</h2><p>利用超声波避障的传感器，能力消耗较缓慢，在介质中传播距离较远，穿透性强，测距的方法简单，成本低。超声波传感器探测距离为1-5米，一般用于数据简单、对实时性要求高的场景，如倒车报警系统、近距离障碍物检测。</p><h2 id="2-5、惯性导航系统"><a href="#2-5、惯性导航系统" class="headerlink" title="2.5、惯性导航系统"></a>2.5、惯性导航系统</h2><p>上面介绍的传感器都是闭环的，即从周边环境获取信息输送给车载处理器，处理器根据获取的信息作出决策和反馈。而惯性导航系统不依赖于外部信息，而是以陀螺仪和加速度计为敏感器件的导航参数解算系统，该系统根据陀螺仪的输出建立导航坐标系，根据加速度计的输出解算出运载体在导航坐标系中的速度和位置。惯性导航系统以牛顿力学定律为基础，是一种推导式的导航方式。惯性导航在室内、隧道内等GPS信号较弱的场景有着广泛的应用。由于不需要接收外界的信号，惯性导航的隐蔽性较好，且基本不受天气条件的限制。</p><p>惯性导航系统的缺点也很明显，由于定位信息是通过对时间的积分获得的，因此误差会随着时间的积累而增加，因此需要利用外部信息进行校正。</p><h1 id="3、数据融合"><a href="#3、数据融合" class="headerlink" title="3、数据融合"></a>3、数据融合</h1><p>数据融合的前提是各种传感器之间的标定，其目的是实现各个传感器坐标系之间的转换，将不同传感器映射到同一个时空参考系中。传感器标定是融合到基础，包括标定每个传感器本身以及求得各个传感器坐标系之间的相互转换关系。</p><p>以激光雷达标定和摄像头标定为例，激光雷达标定是指激光雷达的坐标映射到统一车体坐标系中以便于数据处理。在行驶过程中，汽车和激光雷达的相对位置一般保持不变，即刚性连接，因此可以首先获得激光雷达外部的参数，然后通过激光雷达得到的极坐标完成单个激光雷达数据的映射，最后完成多个激光雷达数据的映射。摄像头标定主要是完成图片中的像素点坐标与真实环境所处位置之间的映射关系。</p>]]></content>
      
      
      <categories>
          
          <category> 自动驾驶 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 自动驾驶 </tag>
            
            <tag> 环境感知概述 </tag>
            
            <tag> 感知系统组成 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
